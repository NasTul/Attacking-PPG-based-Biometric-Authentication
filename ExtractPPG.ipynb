{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqSuXN+hoD7lsjBdpK1srm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Mount Cloud Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","# Install environment\n","!pip install pyvhr\n","!pip uninstall -y tensorflow keras tf-nightly keras-nightly\n","!pip install tensorflow\n","\n","# -- Modules and packages to import for demo\n","from pyVHR.signals.video import Video\n","from pyVHR.methods.pos import POS\n","from pyVHR.methods.chrom import CHROM\n","\n","import numpy as np\n","import ast\n","import plotly.graph_objects as go\n","from scipy.signal import medfilt, detrend\n","from abc import ABCMeta, abstractmethod\n","from importlib import import_module\n","from pyVHR.signals.bvp import BVPsignal\n","from pyVHR.utils import filters, printutils\n","from pyVHR.utils import detrending"],"metadata":{"id":"o8Umrqc4A4Y6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7C3YbuQjA4ge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get rPPG"],"metadata":{"id":"kA-HeGmeA6JP"}},{"cell_type":"code","source":["def readparams( **kwargs):\n","    \n","    # get params from kwargs or set default\n","    if 'startTime' in kwargs:\n","        startTime = float(kwargs['startTime'])\n","    else:\n","        startTime = 0\n","    if 'endTime' in kwargs:\n","        if kwargs['endTime']=='INF':\n","            endTime = np.Inf\n","        else:\n","            endTime = float(kwargs['endTime'])\n","    else:\n","        endTime=np.Inf\n","    if 'winSize' in kwargs:\n","        winSize = int(kwargs['winSize'])\n","    else:\n","        winSize = 10\n","    if 'timeStep' in kwargs:\n","        timeStep = float(kwargs['timeStep'])\n","    else:\n","        timeStep = 10\n","    if 'zeroMeanSTDnorm' in kwargs:\n","        zeroMeanSTDnorm = int(kwargs['zeroMeanSTDnorm'])\n","    else:\n","        zeroMeanSTDnorm = 0\n","    if 'BPfilter' in kwargs:\n","        BPfilter = int(kwargs['BPfilter'])\n","    else:\n","        BPfilter = 1\n","    if 'minHz' in kwargs:\n","        minHz = float(kwargs['minHz'])\n","    else:\n","        minHz = .75\n","    if 'maxHz' in kwargs:\n","        maxHz = float(kwargs['maxHz'])\n","    else:\n","        maxHz = 4.\n","    if 'detrending' in kwargs:\n","        detrending = int(kwargs['detrending'])\n","    else:\n","        detrending = 0\n","    if detrending:\n","        if 'detrLambda' in kwargs:\n","            detrLambda = kwargs['detrLambda']\n","        else:\n","            detrLambda = 10\n","    else:\n","        detrLambda = 10\n","    if 'detrMethod' in kwargs:\n","        detrMethod = kwargs['detrMethod']\n","    else:\n","        detrMethod = 'tarvainen'\n","        \n","    return startTime, endTime, winSize, timeStep, zeroMeanSTDnorm, BPfilter, minHz, maxHz,\\\n","            detrending, detrMethod, detrLambda\n","\n","\n","\n","\n"," \n","def getEsignal(rPPG_m):\n","    startTime, endTime, winSize, timeStep, zeroMeanSTDnorm, BPfilter, minHz, maxHz, detrFilter, \\\n","    detrMethod, detrLambda = readparams(**params)  \n","\n","\n","    count = 0\n","\n","    if endTime > video.duration:\n","        endTime = video.duration\n","        \n","    assert startTime <= endTime, \"Time interval error!\"\n","\n","    if video.doEVM is True:\n","        video.applyEVM()\n","    else:\n","        video.processedFaces = video.faces\n","\n","\n","    fs = video.frameRate\n","    startFrame = 0\n","    arr_sigRGB = []\n","    arr_sigRGB_more = []\n","    rPPG_arr = []\n","    # -- loop on video signal chunks\n","\n","    endFrame =  int(endTime*video.frameRate)\n","\n","    # -- extract ROIs on the frame range\n","    frameSubset = np.arange(startFrame, video.numFrames)\n","\n","    ROImask = params['ROImask']\n","\n","    # -- type of signal extractor\n","    if ROImask == 'rect':\n","        rects = ast.literal_eval(params['rectCoords'])\n","        rectCoords = []\n","        for x in rects:\n","            rect = []\n","            for y in x:\n","                rect.append(int(y))\n","            rectCoords.append(rect)\n","        video.setMask(ROImask, rectCoords=rectCoords)\n","    elif ROImask == 'skin_adapt':\n","        video.setMask(ROImask, skinThresh_adapt=float(params['skinAdapt']))\n","    elif ROImask == 'skin_fix':\n","        threshs = ast.literal_eval(params['skinFix'])\n","        threshSkinFix = [int(x) for x in threshs]\n","        video.setMask(ROImask, skinThresh_fix=threshSkinFix)\n","    else:\n","        raise ValueError(ROImask + \" : Unimplemented Signal Extractor!\")\n","        \n","    video.extractSignal(frameSubset, count)\n","\n","\n","    # -- RGB computation  \n","    RGBsig = video.getMeanRGB()\n","\n","    # -- RGB raw data\n","    arr_sigRGB.append(RGBsig)\n","        \n","        \n","    # -- RGBsig preprocessing\n","    if zeroMeanSTDnorm:\n","        RGBsig = filters.zeroMeanSTDnorm(RGBsig)      \n","    if detrFilter:\n","        if detrMethod == 'tarvainen':\n","            #TODO controllare il detrending di tarvainen\n","            RGBsig[0] = detrending.detrend(RGBsig[0], detrLambda)\n","            RGBsig[1] = detrending.detrend(RGBsig[1], detrLambda)\n","            RGBsig[2] = detrending.detrend(RGBsig[2], detrLambda)\n","        else:\n","            RGBsig = detrend(RGBsig)\n","    if BPfilter:\n","        RGBsig = filters.BPfilter(RGBsig, minHz, maxHz, fs)\n","        \n","\n","    # -- apply the selected method \n","    arr_sigRGB_more.append(RGBsig)\n","\n","\n","    rPPG = rPPG_m.apply(RGBsig)\n","    # rPPG = apply(RGBsig)\n","\n","    rPPG_arr.append(rPPG)   \n","\n","\n","    return  arr_sigRGB, arr_sigRGB_more, rPPG_arr\n"],"metadata":{"id":"68frlsbS7uzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If don't have enough resources, we can split the video\n","# Replace path\n","\n","import os\n","from tqdm import tqdm\n","for i in tqdm(range(50,57)) :\n","    number = str(i)\n","    # if 'vid_s'+number+'_1' not in  list_dir:\n","    os.mkdir('xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_1/')\n","    cmd1 = 'ffmpeg -ss 0 -i '+'xxx/UBFC_data/Origin/s'+number+'/vid_s'+number+'_T3.avi -t 60 -c:v copy -c:a copy xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_1/vid_s'+number+'_T3_1.avi'\n","    res = os.popen(cmd1)\n","    print(res.read())\n","    # if 'vid_s'+number+'_2' not in  list_dir:\n","    os.mkdir('xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_2/')\n","    cmd2 = 'ffmpeg -ss 60 -i '+'xxx/UBFC_data/Origin/s'+number+'/vid_s'+number+'_T3.avi -t 60 -c:v copy -c:a copy xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_2/vid_s'+number+'_T3_2.avi'\n","    res = os.popen(cmd2)\n","    print(res.read())\n","    # if 'vid_s'+number+'_3' not in  list_dir:\n","    os.mkdir('xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_3/')\n","    cmd3 = 'ffmpeg -ss 120 -i '+'xxx/UBFC_data/Origin/s'+number+'/vid_s'+number+'_T3.avi -t 60 -c:v copy -c:a copy xxx/UBFC_data/SplitVideo_T3/vid_s'+number+'_3/vid_s'+number+'_T3_3.avi'\n","    res = os.popen(cmd3)\n","    print(res.read())"],"metadata":{"id":"IpU5imxm-mEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UPybptxl_3WO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get video list\n","import os\n","data_list = os.listdir('xxx/UBFC_data/SplitVideo_T3')\n"],"metadata":{"id":"J6TWX1rE_3Ya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","from tqdm import tqdm\n","error_list = []\n","file_list = []\n","data_x=[]\n","data_y=[]\n","cycle_ppg = []\n","for sub_data in tqdm(data_list):\n","  try:\n","    number = int(sub_data.split('_')[1][1:]) \n","    num = int(sub_data.split('_')[2])\n","    # -- Video object\n","    videoFilename = \"xxx/UBFC_data/SplitVideo_T3/\"+sub_data + \"/vid_s\"+ str(number)+\"_T3_\"+str(num)+\".avi\"\n","    video = Video(videoFilename)\n","    # -- extract faces\n","    video.getCroppedFaces(detector='mtcnn_kalman', extractor='skvideo')\n","    video.printVideoInfo()\n","  except:\n","    print(sub_data)\n","    error_list.append(sub_data)\n","    continue\n","\n","  params = {\"video\": video, \"verb\":2, \"ROImask\":\"skin_adapt\", \"skinAdapt\":0.2}\n","  m=CHROM(**params)\n","  arr_sigRGB, arr_sigRGB_more, rPPG_arr = getEsignal(m)\n","  bvpChunk = BVPsignal(np.array(rPPG_arr[0]), 35, 0)\n","  bvpChunk.findPeaks()\n","  low_point = []\n","  before = 0\n","  minnumber = 0 \n","  for i in bvpChunk.peaks:\n","    index_ = np.argmin(bvpChunk.data[0][before:i])\n","    low_point.append(index_+before)\n","    before = i\n","\n","  index_ = np.argmin(bvpChunk.data[0][before:-1])\n","  low_point.append(index_+before)\n","\n","\n","  for index, i in  enumerate(low_point):\n","    if index==0:\n","      continue \n","    cycle_ppg.append(bvpChunk.data[0][low_point[index-1]:low_point[index]])\n","    data_y.append(number)\n","\n","      \n","  file_open=open('xxx/UBFC_data/cycle_ppg_UBFC_T3.pl','wb')\n","  pickle.dump((cycle_ppg,data_y),file_open)\n","  file_open.close()"],"metadata":{"id":"E3-_RaW1-oGv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZulyXsJl-oJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"epKhA_AV7u4H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get GT PPG"],"metadata":{"id":"3XE1_GbbBDcM"}},{"cell_type":"code","source":["import numpy as np\n","from scipy.signal import find_peaks, stft, lfilter, butter, welch\n","from plotly.subplots import make_subplots\n","from plotly.colors import n_colors\n","import plotly.graph_objects as go\n","from scipy.interpolate import interp1d"],"metadata":{"id":"SV7ADqaYBFAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BVPsignal:\n","    \"\"\"\n","        Manage (multi-channel, row-wise) BVP signals\n","    \"\"\"\n","    nFFT = 2048  # freq. resolution for STFTs\n","    step = 1       # step in seconds\n","\n","    def __init__(self, data, fs, startTime=0, minHz=0.75, maxHz=4., verb=False):\n","        if len(data.shape) == 1:\n","            self.data = data.reshape(1,-1) # 2D array raw-wise\n","        else:\n","            self.data = data\n","        self.numChls = self.data.shape[0]  # num  channels\n","        self.fs = fs                       # sample rate\n","        self.startTime = startTime\n","        self.verb = verb\n","        self.minHz = minHz\n","        self.maxHz = maxHz\n","\n","    def getChunk(startTime, winsize=None, numSample=None):\n","        \n","        assert startTime >= self.startTime, \"Start time error!\"\n","        \n","        N = self.data.shape[1] \n","        fs = self.fs\n","        Nstart = int(fs*startTime)\n","        \n","        # -- winsize > 0\n","        if winsize:\n","            stopTime = startTime + winsize\n","            Nstop = np.min([int(fs*stopTime),N])\n","            \n","        # -- numSample > 0\n","        if numSample:\n","            Nstop = np.min([numSample,N])\n","        \n","        return self.data[0,Nstart:Nstop]\n","        \n","    def hps(self, spect, d=3):\n","        \n","        if spect.ndim == 2:\n","            n_win = spect.shape[1]\n","            new_spect = np.zeros_like(spect)\n","            for w in range(n_win):\n","                curr_w = spect[:,w]\n","                w_down_z = np.zeros_like(curr_w)\n","                w_down = curr_w[::d]\n","                w_down_z[0:len(w_down)] = w_down\n","                w_hps = np.multiply(curr_w, w_down_z)\n","                new_spect[:, w] = w_hps\n","            return new_spect\n","\n","        elif spect.ndim == 1:\n","            s_down_z = np.zeros_like(spect)\n","            s_down = spect[::d]\n","            s_down_z[0:len(s_down)] = s_down\n","            w_hps = np.multiply(spect, s_down_z)\n","            return w_hps\n","\n","        else:\n","            raise ValueError(\"Wrong Dimensionality of the Spectrogram for the HPS\")\n","\n","    def spectrogram(self, winsize=5, use_hps=False):\n","        \"\"\"\n","        Compute the BVP signal spectrogram restricted to the\n","        band 42-240 BPM by using winsize (in sec) samples.\n","        \"\"\"\n","\n","        # -- spect. Z is 3-dim: Z[#chnls, #freqs, #times]\n","        F, T, Z = stft(self.data,\n","                       self.fs,\n","                       nperseg=self.fs*winsize,\n","                       noverlap=self.fs*(winsize-self.step),\n","                       boundary='even',\n","                       nfft=self.nFFT)\n","        Z = np.squeeze(Z, axis=0)\n","\n","        # -- freq subband (0.75 Hz - 4.0 Hz)\n","        minHz = 0.75\n","        maxHz = 4.0\n","        band = np.argwhere((F > minHz) & (F < maxHz)).flatten()\n","        self.spect = np.abs(Z[band,:])     # spectrum magnitude\n","        self.freqs = 60*F[band]            # spectrum freq in bpm\n","        self.times = T                     # spectrum times\n","\n","        if use_hps:\n","            spect_hps = self.hps(self.spect)\n","            # -- BPM estimate by spectrum\n","            self.bpm = self.freqs[np.argmax(spect_hps,axis=0)]\n","        else:\n","            # -- BPM estimate by spectrum\n","            self.bpm = self.freqs[np.argmax(self.spect,axis=0)]\n","        \n","    def getBPM(self, winsize=5):\n","        self.spectrogram(winsize, use_hps=False)\n","        return self.bpm, self.times\n","    \n","    def PSD2BPM(self, chooseBest=True, use_hps=False):\n","        \"\"\"\n","            Compute power spectral density using Welch’s method and estimate\n","            BPMs from video frames\n","        \"\"\"\n","\n","        # -- interpolation for less than 256 samples\n","        c,n = self.data.shape\n","        if n < 256:\n","            seglength = n\n","            overlap = int(0.8*n)  # fixed overlapping\n","        else:\n","            seglength = 256\n","            overlap = 200\n","       \n","        # -- periodogram by Welch\n","        F, P = welch(self.data, nperseg=seglength, noverlap=overlap, window='hamming',fs=self.fs, nfft=self.nFFT)\n","\n","        # -- freq subband (0.75 Hz - 4.0 Hz)\n","        band = np.argwhere((F > self.minHz) & (F < self.maxHz)).flatten()\n","        self.Pfreqs = 60*F[band]\n","        self.Power = P[:,band]\n","        \n","        # -- if c = 3 choose that with the best SNR\n","        if chooseBest:\n","            winner = 0\n","            lobes = self.PDSrippleAnalysis(ch=0)\n","            SNR = lobes[-1]/lobes[-2]\n","            if c == 3:\n","                lobes = self.PDSrippleAnalysis(ch=1)\n","                SNR1 = lobes[-1]/lobes[-2]\n","                if SNR1 > SNR:\n","                    SNR = SNR1\n","                    winner = 1\n","                lobes = self.PDSrippleAnalysis(ch=2)\n","                SNR1 = lobes[-1]/lobes[-2]\n","                if SNR1 > SNR:\n","                    SNR = SNR1\n","                    winner = 2    \n","            self.Power = self.Power[winner].reshape(1,-1)\n","        \n","        # TODO: eliminare?\n","        if use_hps:\n","            p = self.Power[0]\n","            phps = self.hps(p)\n","            '''import matplotlib.pyplot as plt\n","            plt.plot(p)\n","            plt.figure()\n","            plt.plot(phps)\n","            plt.show()'''\n","            Pmax = np.argmax(phps)  # power max\n","            self.bpm = np.array([self.Pfreqs[Pmax]])       # freq max\n","\n","        else:\n","            # -- BPM estimate by PSD\n","            Pmax = np.argmax(self.Power, axis=1)  # power max\n","            self.bpm = self.Pfreqs[Pmax]       # freq max\n","\n","        if '3' in str(self.verb):\n","            lobes = self.PDSrippleAnalysis()\n","            self.displayPSD(lobe1=lobes[-1], lobe2=lobes[-2])\n","\n","    def autocorr(self):\n","        from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","\n","        # TODO: to handle all channels\n","        x = self.data[0,:]\n","        plot_acf(x)\n","        plt.show()\n","\n","        plot_pacf(x)\n","        plt.show()\n","\n","    def displaySpectrum(self, display=False, dims=3):\n","        \"\"\"Show the spectrogram of the BVP signal\"\"\"\n","\n","        # -- check if bpm exists\n","        try:\n","            bpm = self.bpm\n","        except AttributeError:\n","            self.spectrogram()\n","            bpm = self.bpm\n","            \n","        t = self.times\n","        f = self.freqs\n","        S = self.spect\n","\n","        fig = go.Figure()\n","        fig.add_trace(go.Heatmap(z=S, x=t, y=f, colorscale=\"viridis\"))\n","        fig.add_trace(go.Scatter(x=t, y=bpm, name='Frequency Domain', line=dict(color='red', width=2)))\n","\n","        fig.update_layout(autosize=False, height=420, showlegend=True,\n","                          title='Spectrogram of the BVP signal',\n","                          xaxis_title='Time (sec)',\n","                          yaxis_title='BPM (60*Hz)',\n","                          legend=dict(\n","                            x=0,\n","                            y=1,\n","                            traceorder=\"normal\",\n","                            font=dict(\n","                                family=\"sans-serif\",\n","                                size=12,\n","                                color=\"black\"),\n","                            bgcolor=\"LightSteelBlue\",\n","                            bordercolor=\"Black\",\n","                            borderwidth=2)\n","                         )\n","                       \n","        fig.show()\n","\n","    def findPeaks(self, distance=None, height=None):\n","        \n","        # -- take the first channel\n","        x = self.data[0].flatten()\n","            \n","        if distance is None:\n","            distance = self.fs/2\n","        if height is None:\n","            height = np.mean(x)\n","\n","        # -- find peaks with the specified params\n","        self.peaks, _ = find_peaks(x, distance=distance, height=height)\n","        \n","        self.peaksTimes = self.peaks/self.fs\n","        self.bpmPEAKS = 60.0/np.diff(self.peaksTimes)\n","        \n","    def plotBPMPeaks(self, height=None, width=None):\n","        \"\"\"\n","            Plot the the BVP signal and peak marks\n","        \"\"\"\n","\n","        # -- find peaks  \n","        try:\n","            peaks = self.peaks\n","        except AttributeError:\n","            self.findPeaks()\n","            peaks = self.peaks\n","        \n","        #-- signals \n","        y = self.data[0]\n","        n = y.shape[0]\n","        startTime  = self.startTime \n","        stopTime = startTime+n/self.fs\n","        x = np.linspace(startTime, stopTime, num=n, endpoint=False)\n","        \n","        fig = go.Figure()\n","        fig.add_trace(go.Scatter(x=x, y=y, name=\"BVP\"))\n","        fig.add_trace(go.Scatter(x=x[peaks], y=y[peaks], mode='markers', name=\"Peaks\"))\n","\n","        if not height:\n","            height=400\n","        if not width:\n","            width=800\n","\n","        fig.update_layout(height=height, width=width, title=\"BVP signal + peaks\",\n","            font=dict(\n","                family=\"Courier New, monospace\",\n","                size=14,\n","                color=\"#7f7f7f\"))\n","        \n","        fig.show()\n","        \n","    def plot(self, title=\"BVP signal\", height=400, width=800):\n","        \"\"\"\n","            Plot the the BVP signal (multiple channels)\n","        \"\"\"\n","      \n","        #-- signals \n","        y = self.data\n","        c,n = y.shape\n","        startTime  = self.startTime \n","        stopTime = startTime+n/self.fs\n","        x = np.linspace(startTime, stopTime, num=n, endpoint=False)\n","        \n","        fig = go.Figure()\n","        \n","        for i in range(c):\n","            name = \"BVP \" + str(i)\n","            fig.add_trace(go.Scatter(x=x, y=y[i], name=name))\n","\n","        fig.update_layout(height=height, width=width, title=title,\n","            font=dict(\n","                family=\"Courier New, monospace\",\n","                size=14,\n","                color=\"#7f7f7f\"))\n","        fig.show()\n","        \n","    def displayPSD(self, ch=0, lobe1=None, lobe2=None, GT=None):\n","        \"\"\"Show the periodogram(s) of the BVP signal for channel ch\"\"\"\n","\n","        f = self.Pfreqs \n","        P = self.Power[ch] \n","                \n","        fig = go.Figure()\n","        \n","        fig.add_trace(go.Scatter(x=f, y=P, name='PSD'))\n","        fig.update_layout(autosize=False, width=500, height=400)\n","        \n","        if lobe1 is not None and lobe2 is not None:\n","            L1 = lobe1\n","            L2 = lobe2\n","            # Add horiz. lobe peack lines\n","            fig.add_shape(type=\"line\",x0=f[0], y0=L1, x1=f[-1], y1=L1,\n","                line=dict(color=\"LightSeaGreen\", width=2, dash=\"dashdot\"))\n","            fig.add_shape(type=\"line\",x0=f[0], y0=L2, x1=f[-1], y1=L2,\n","                line=dict(color=\"SeaGreen\", width=2, dash=\"dashdot\"))\n","            tit = 'SNR = ' + str(np.round(L1/L2,2))\n","            fig.update_layout(title=tit)\n","            \n","        if GT is not None:\n","            # Add vertical GT line\n","            fig.add_shape(type=\"line\",x0=GT, y0=0, x1=GT, y1=np.max(P),\n","                line=dict(color=\"DarkGray\", width=2, dash=\"dash\"))\n","            \n","        fig.show()\n","  \n","    def PDSrippleAnalysis(self, ch=0):\n","        # -- ripple analysis\n","        \n","        P = self.Power[ch].flatten()\n","        dP = np.gradient(P)\n","        n = len(dP)\n","        I = []; \n","        i = 0\n","        while i < n:\n","            m = 0\n","            # -- positive gradient\n","            while (i < n) and (dP[i] > 0):\n","                m = max([m,P[i]])\n","                i += 1\n","            I.append(m)\n","            # -- skip negative gradient\n","            while (i < n) and (dP[i] < 0) : \n","                i += 1\n","        lobes = np.sort(I)\n","        if len(lobes) < 2:\n","            lobes = np.array([lobes,0])\n","            \n","        return lobes"],"metadata":{"id":"aCcKLmIrBHcy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pnuiSDdBBhrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","data_x=[]\n","data_y=[]\n","cycle_ppg = []\n","for file_num in range(1,57):\n","\n","  with open('xxx/UBFC_data/Origin/s'+str(file_num)+'/bvp_s'+ str(file_num) +'_T3.csv','r') as csvfile:\n","      reader = csv.reader(csvfile)\n","      rows= []\n","      for row in reader:\n","        #when not vid\n","        for sub_row in row:\n","          rows.append(float(sub_row))\n","          # rows.append(float(row[0]))\n","  rows_arr = np.array(rows)\n","\n","  bvpChunk = BVPsignal(rows_arr, 64, 0)\n","  bvpChunk.findPeaks()\n","\n","\n","  low_point = []\n","  before = 0\n","  minnumber = 0 \n","  for i in bvpChunk.peaks:\n","    index_ = np.argmin(bvpChunk.data[0][before:i])\n","    low_point.append(index_+before)\n","    before = i\n","\n","  index_ = np.argmin(bvpChunk.data[0][before:-1])\n","  low_point.append(index_+before)\n","\n","  \n","  for index, i in  enumerate(low_point):\n","    if index==0:\n","      continue \n","    cycle_ppg.append(bvpChunk.data[0][low_point[index-1]:low_point[index]])\n","    data_y.append(file_num)\n","\n","\n","\n","\n","  file_open=open('xxx/UBFC_data/cycle_ppg_UBFC_T3.pl','wb')\n","  pickle.dump((cycle_ppg,data_y),file_open)\n","  file_open.close()"],"metadata":{"id":"5_lKPvTKBIPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iFRv0jT5BHil"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get different video qualities"],"metadata":{"id":"Tvu1wPAFVMNh"}},{"cell_type":"code","source":["# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 227474k  -s 1024x1024   -r 30   vid1.avi\n","# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 227474k  -s 1024x1024   -r 20   vid2.avi\n","# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 227474k  -s 512x512   -r 35.14   vid3.avi\n","# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 227474k  -s 256x256   -r 35.14 vid4.avi\n","# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 113737k  -s 1024x1024   -r 35.14   vid5.avi\n","# ffmpeg -i  vid_s10_T1_1.avi -vcodec mjpeg -b 255k  -s 1024x1024   -r 35.14   vid6.avi"],"metadata":{"id":"w_I5R1XyBHkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Uqng3figVK2S"},"execution_count":null,"outputs":[]}]}